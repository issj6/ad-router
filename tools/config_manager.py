#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ–‡ä»¶é…ç½®ç®¡ç†å·¥å…·

åŠŸèƒ½:
- å°†å•æ–‡ä»¶é…ç½®æ‹†åˆ†ä¸ºå¤šæ–‡ä»¶
- éªŒè¯å¤šæ–‡ä»¶é…ç½®
- åˆå¹¶å¤šæ–‡ä»¶é…ç½®ä¸ºå•æ–‡ä»¶
- æ·»åŠ æ–°çš„ä¸Šæ¸¸é…ç½®
"""

import sys
import yaml
import json
import argparse
from pathlib import Path
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    def split_config(self, source_file: str, output_dir: str) -> None:
        """å°†å•æ–‡ä»¶é…ç½®æ‹†åˆ†ä¸ºå¤šæ–‡ä»¶"""
        source_path = Path(source_file)
        output_path = Path(output_dir)
        
        if not source_path.exists():
            raise FileNotFoundError(f"æºé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {source_file}")
        
        # åˆ›å»ºç›®å½•ç»“æ„
        (output_path / "upstreams").mkdir(parents=True, exist_ok=True)
        (output_path / "downstreams").mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½æºé…ç½®
        with open(source_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        print(f"ğŸ“„ æ­£åœ¨æ‹†åˆ†é…ç½®æ–‡ä»¶: {source_file}")
        
        # æ‹†åˆ†ä¸Šæ¸¸é…ç½®
        upstreams = config.get("upstreams", [])
        upstream_configs = []
        
        for upstream in upstreams:
            upstream_id = upstream["id"]
            upstream_name = upstream.get("name", upstream_id)
            upstream_file = output_path / "upstreams" / f"{upstream_id}.yaml"
            
            # å†™å…¥ä¸Šæ¸¸é…ç½®æ–‡ä»¶
            with open(upstream_file, 'w', encoding='utf-8') as f:
                yaml.dump(upstream, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
            
            # è®°å½•é…ç½®å¼•ç”¨ï¼ˆåŒ…å«IDå’Œåç§°ï¼‰
            upstream_configs.append({
                "id": upstream_id,
                "name": upstream_name,
                "source": "local",
                "path": f"upstreams/{upstream_id}.yaml",
                "required": True,  # é»˜è®¤æ ‡è®°ä¸ºå¿…éœ€
                "enabled": True    # é»˜è®¤å¯ç”¨
            })
            
            print(f"  âœ… åˆ›å»ºä¸Šæ¸¸é…ç½®: {upstream_file}")
        
        # æ‹†åˆ†ä¸‹æ¸¸é…ç½®ï¼ˆå¦‚æœæœ‰ï¼‰
        downstreams = config.get("downstreams", [])
        downstream_configs = []
        
        for downstream in downstreams:
            downstream_id = downstream["id"]
            downstream_name = downstream.get("name", downstream_id)
            downstream_file = output_path / "downstreams" / f"{downstream_id}.yaml"
            
            with open(downstream_file, 'w', encoding='utf-8') as f:
                yaml.dump(downstream, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
            
            downstream_configs.append({
                "id": downstream_id,
                "name": downstream_name,
                "source": "local",
                "path": f"downstreams/{downstream_id}.yaml",
                "required": True,
                "enabled": True
            })
            
            print(f"  âœ… åˆ›å»ºä¸‹æ¸¸é…ç½®: {downstream_file}")
        
        # åˆ›å»ºä¸»é…ç½®æ–‡ä»¶
        main_config = {
            "settings": config.get("settings", {}),
            "upstream_configs": upstream_configs,
            "downstream_configs": downstream_configs,
            "routes": config.get("routes", [])
        }
        
        main_file = output_path / "main.yaml"
        with open(main_file, 'w', encoding='utf-8') as f:
            yaml.dump(main_config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
        
        print(f"\nâœ… é…ç½®æ‹†åˆ†å®Œæˆ:")
        print(f"   ä¸»é…ç½®: {main_file}")
        print(f"   ä¸Šæ¸¸é…ç½®: {len(upstream_configs)} ä¸ª")
        for uc in upstream_configs:
            print(f"     - {uc['id']}: {uc['name']}")
        if downstream_configs:
            print(f"   ä¸‹æ¸¸é…ç½®: {len(downstream_configs)} ä¸ª")
            for dc in downstream_configs:
                print(f"     - {dc['id']}: {dc['name']}")
        print(f"\nğŸ“– ä½¿ç”¨æ–¹æ³•:")
        print(f"   export CONFIG_DIR={output_path.absolute()}")
        print(f"   python app/main.py")
    
    def validate_config(self, config_dir: str) -> bool:
        """éªŒè¯å¤šæ–‡ä»¶é…ç½®"""
        try:
            from app.config import MultiConfigLoader
            
            print(f"ğŸ” æ­£åœ¨éªŒè¯å¤šæ–‡ä»¶é…ç½®: {config_dir}")
            loader = MultiConfigLoader(local_config_dir=config_dir)
            config = loader.load_config()
            
            print("âœ… é…ç½®éªŒè¯é€šè¿‡")
            print(f"   è®¾ç½®: {len(config.get('settings', {}))} é¡¹")
            print(f"   ä¸Šæ¸¸: {len(config.get('upstreams', []))} ä¸ª")
            print(f"   ä¸‹æ¸¸: {len(config.get('downstreams', []))} ä¸ª")
            print(f"   è·¯ç”±: {len(config.get('routes', []))} æ¡")
            
            # æ˜¾ç¤ºåŠ è½½çš„ä¸Šæ¸¸è¯¦æƒ…
            if config.get('upstreams'):
                print("\nğŸ“‹ å·²åŠ è½½çš„ä¸Šæ¸¸:")
                for upstream in config['upstreams']:
                    metadata = upstream.get('_metadata', {})
                    print(f"   - {upstream['id']}: {metadata.get('name', upstream['id'])}")
                    print(f"     æ¥æº: {metadata.get('source', 'unknown')} <- {metadata.get('loaded_from', 'unknown')}")
            
            return True
            
        except Exception as e:
            print(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {e}")
            return False
    
    def merge_config(self, config_dir: str, output_file: str) -> None:
        """åˆå¹¶å¤šæ–‡ä»¶é…ç½®ä¸ºå•æ–‡ä»¶"""
        try:
            from app.config import MultiConfigLoader
            
            print(f"ğŸ”„ æ­£åœ¨åˆå¹¶å¤šæ–‡ä»¶é…ç½®: {config_dir}")
            loader = MultiConfigLoader(local_config_dir=config_dir)
            config = loader.load_config()
            
            # æ¸…ç†å…ƒæ•°æ®
            for upstream in config.get('upstreams', []):
                upstream.pop('_metadata', None)
            for downstream in config.get('downstreams', []):
                downstream.pop('_metadata', None)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
            
            print(f"âœ… é…ç½®åˆå¹¶å®Œæˆ: {output_file}")
            
        except Exception as e:
            print(f"âŒ é…ç½®åˆå¹¶å¤±è´¥: {e}")
            raise
    
    def add_upstream(self, config_dir: str, upstream_id: str, upstream_name: str = None, template: str = "basic") -> None:
        """æ·»åŠ æ–°çš„ä¸Šæ¸¸é…ç½®"""
        config_path = Path(config_dir)
        upstream_file = config_path / "upstreams" / f"{upstream_id}.yaml"
        main_file = config_path / "main.yaml"
        
        if upstream_file.exists():
            print(f"âŒ ä¸Šæ¸¸é…ç½®å·²å­˜åœ¨: {upstream_file}")
            return
        
        if not main_file.exists():
            print(f"âŒ ä¸»é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {main_file}")
            return
        
        # åˆ›å»ºä¸Šæ¸¸é…ç½®æ¨¡æ¿
        templates = {
            "basic": {
                "id": upstream_id,
                "name": upstream_name or upstream_id,
                "description": f"{upstream_name or upstream_id} å¹¿å‘Šå¹³å°",
                "secrets": {
                    "secret": f"{upstream_id}_secret_key"
                },
                "adapters": {
                    "outbound": {
                        "click": {
                            "method": "GET",
                            "url": f"https://api.{upstream_id}.com/click?aid={{{{aid}}}}&ts={{{{ts}}}}&callback={{{{callback}}}}",
                            "macros": {
                                "aid": "udm.ad.ad_id | url_encode()",
                                "ts": "udm.time.ts",
                                "callback": "cb_url() | url_encode()"
                            },
                            "timeout_ms": 3000,
                            "retry": {"max": 2, "backoff_ms": 500}
                        }
                    },
                    "inbound_callback": {
                        "event": {
                            "source": "query",
                            "field_map": {
                                "udm.event.type": "const:event",
                                "udm.event.name": "query.event_type",
                                "udm.time.ts": "now_ms()"
                            }
                        }
                    }
                }
            }
        }
        
        upstream_config = templates.get(template, templates["basic"])
        
        # å†™å…¥ä¸Šæ¸¸é…ç½®æ–‡ä»¶
        upstream_file.parent.mkdir(exist_ok=True)
        with open(upstream_file, 'w', encoding='utf-8') as f:
            yaml.dump(upstream_config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
        
        # æ›´æ–°ä¸»é…ç½®æ–‡ä»¶
        with open(main_file, 'r', encoding='utf-8') as f:
            main_config = yaml.safe_load(f)
        
        upstream_configs = main_config.get("upstream_configs", [])
        upstream_configs.append({
            "id": upstream_id,
            "name": upstream_name or upstream_id,
            "source": "local",
            "path": f"upstreams/{upstream_id}.yaml",
            "required": True,
            "enabled": True
        })
        
        main_config["upstream_configs"] = upstream_configs
        
        with open(main_file, 'w', encoding='utf-8') as f:
            yaml.dump(main_config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
        
        print(f"âœ… æ–°ä¸Šæ¸¸é…ç½®å·²æ·»åŠ :")
        print(f"   é…ç½®æ–‡ä»¶: {upstream_file}")
        print(f"   ä¸Šæ¸¸ID: {upstream_id}")
        print(f"   æ˜¾ç¤ºå: {upstream_name or upstream_id}")
        print(f"\nğŸ“ ä¸‹ä¸€æ­¥:")
        print(f"   1. ç¼–è¾‘ {upstream_file} å®Œå–„é…ç½®")
        print(f"   2. åœ¨ {main_file} çš„ routes ä¸­æ·»åŠ è·¯ç”±è§„åˆ™")
    
    def list_upstreams(self, config_dir: str) -> None:
        """åˆ—å‡ºæ‰€æœ‰ä¸Šæ¸¸é…ç½®"""
        try:
            from app.config import MultiConfigLoader
            
            loader = MultiConfigLoader(local_config_dir=config_dir)
            config = loader.load_config()
            
            upstreams = config.get('upstreams', [])
            if not upstreams:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ä¸Šæ¸¸é…ç½®")
                return
            
            print(f"ğŸ“‹ ä¸Šæ¸¸é…ç½®åˆ—è¡¨ ({len(upstreams)} ä¸ª):")
            for upstream in upstreams:
                metadata = upstream.get('_metadata', {})
                print(f"\n  ğŸ”— {upstream['id']}")
                print(f"     åç§°: {metadata.get('name', upstream.get('name', upstream['id']))}")
                print(f"     æè¿°: {upstream.get('description', 'æ— ')}")
                print(f"     æ¥æº: {metadata.get('source', 'unknown')}")
                print(f"     æ–‡ä»¶: {metadata.get('loaded_from', 'unknown')}")
                print(f"     å¿…éœ€: {'æ˜¯' if metadata.get('required', False) else 'å¦'}")
                
                # æ˜¾ç¤ºæ”¯æŒçš„äº‹ä»¶ç±»å‹
                adapters = upstream.get('adapters', {})
                outbound = adapters.get('outbound', {})
                events = list(outbound.keys())
                if events:
                    print(f"     äº‹ä»¶: {', '.join(events)}")
            
        except Exception as e:
            print(f"âŒ åˆ—å‡ºä¸Šæ¸¸é…ç½®å¤±è´¥: {e}")


def main():
    parser = argparse.ArgumentParser(description="å¤šæ–‡ä»¶é…ç½®ç®¡ç†å·¥å…·")
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    # æ‹†åˆ†å‘½ä»¤
    split_parser = subparsers.add_parser("split", help="æ‹†åˆ†å•æ–‡ä»¶é…ç½®")
    split_parser.add_argument("source", help="æºé…ç½®æ–‡ä»¶")
    split_parser.add_argument("output", help="è¾“å‡ºç›®å½•")
    
    # éªŒè¯å‘½ä»¤
    validate_parser = subparsers.add_parser("validate", help="éªŒè¯å¤šæ–‡ä»¶é…ç½®")
    validate_parser.add_argument("config_dir", help="é…ç½®ç›®å½•")
    
    # åˆå¹¶å‘½ä»¤
    merge_parser = subparsers.add_parser("merge", help="åˆå¹¶å¤šæ–‡ä»¶é…ç½®")
    merge_parser.add_argument("config_dir", help="é…ç½®ç›®å½•")
    merge_parser.add_argument("output", help="è¾“å‡ºæ–‡ä»¶")
    
    # æ·»åŠ ä¸Šæ¸¸å‘½ä»¤
    add_parser = subparsers.add_parser("add-upstream", help="æ·»åŠ æ–°çš„ä¸Šæ¸¸é…ç½®")
    add_parser.add_argument("config_dir", help="é…ç½®ç›®å½•")
    add_parser.add_argument("upstream_id", help="ä¸Šæ¸¸ID")
    add_parser.add_argument("--name", help="ä¸Šæ¸¸æ˜¾ç¤ºåç§°")
    add_parser.add_argument("--template", choices=["basic"], default="basic", help="é…ç½®æ¨¡æ¿")
    
    # åˆ—å‡ºä¸Šæ¸¸å‘½ä»¤
    list_parser = subparsers.add_parser("list", help="åˆ—å‡ºæ‰€æœ‰ä¸Šæ¸¸é…ç½®")
    list_parser.add_argument("config_dir", help="é…ç½®ç›®å½•")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    manager = ConfigManager()
    
    try:
        if args.command == "split":
            manager.split_config(args.source, args.output)
        elif args.command == "validate":
            success = manager.validate_config(args.config_dir)
            sys.exit(0 if success else 1)
        elif args.command == "merge":
            manager.merge_config(args.config_dir, args.output)
        elif args.command == "add-upstream":
            manager.add_upstream(args.config_dir, args.upstream_id, args.name, args.template)
        elif args.command == "list":
            manager.list_upstreams(args.config_dir)
        else:
            parser.print_help()
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
